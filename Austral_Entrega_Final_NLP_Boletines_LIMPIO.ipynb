{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKKizVkbUsKc"
   },
   "source": [
    "# Ingesta de Datos de Boletines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar gdown para descargar desde Google Drive\n",
    "!pip install -q gdown\n",
    "\n",
    "# Descargar el archivo ZIP desde Google Drive (ID del archivo)\n",
    "!gdown --id 1VsKDt8KTn7_n_6slX6vYEaOTkloS9UqP --output boletines.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimir el archivo\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"boletines.zip\"\n",
    "extract_folder = \"boletines_extraidos\"\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# Extraer los archivos\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "# Listar archivos extra√≠dos\n",
    "import os\n",
    "archivos = os.listdir(extract_folder)\n",
    "print(\"Archivos extra√≠dos:\")\n",
    "for archivo in archivos:\n",
    "    print(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "carpeta = \"/content/boletines_extraidos/Boletines/boletines_2024\" # aqui va la carpeta en drive donde estan los documentos\n",
    "\n",
    "pdfs = [f for f in os.listdir(carpeta) if f.endswith(\".pdf\")]\n",
    "\n",
    "print(\"PDFs encontrados:\", pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zKGHEV0UzkN"
   },
   "source": [
    "Por cada pdf o boletin se realiza la lectura y separacion de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Procesar cada PDF ---\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for numero in pdfs:\n",
    "    pdf_path = os.path.join(carpeta, numero)\n",
    "    if not os.path.exists(pdf_path):\n",
    "        continue  # Saltar si no se descarg√≥\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        texto_sumario = \"\"\n",
    "\n",
    "        # Ignorar p√°gina 1 y 2\n",
    "        # Ignorar p√°gina 0, 1 y la √∫ltima p√°gina\n",
    "        for i in range(2, len(doc) - 1):\n",
    "            texto_sumario += doc[i].get_text()\n",
    "        #for i in range(2, len(doc)):\n",
    "        #    texto_sumario += doc[i].get_text()\n",
    "\n",
    "        # Patr√≥n que detecta bloques finalizados con OP\n",
    "        patron_op = re.compile(r\"OP\\s*N[¬∞¬∫]:\\s*[A-Z]*\\d{6,}\", re.IGNORECASE)\n",
    "        matches = list(patron_op.finditer(texto_sumario))\n",
    "\n",
    "        if not matches:\n",
    "            documentos = [texto_sumario.strip()]\n",
    "        else:\n",
    "            documentos = []\n",
    "            start_idx = 0\n",
    "            for m in matches:\n",
    "                end_idx = m.end()\n",
    "                bloque = texto_sumario[start_idx:end_idx].strip()\n",
    "                documentos.append(bloque)\n",
    "                start_idx = end_idx\n",
    "            if start_idx < len(texto_sumario):\n",
    "                documentos.append(texto_sumario[start_idx:].strip())\n",
    "\n",
    "        # Extraer OP\n",
    "        def extraer_op_final(texto):\n",
    "            match = re.search(r\"OP\\s*N[¬∞¬∫]:\\s*([A-Z]*\\d{6,})\\s*$\", texto.strip(), re.IGNORECASE)\n",
    "            return match.group(1) if match else None\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"Boletin_N\": numero,\n",
    "            \"Documento_N\": range(1, len(documentos)+1),\n",
    "            \"Texto\": documentos\n",
    "        })\n",
    "\n",
    "        df[\"OP_Numero\"] = df[\"Texto\"].apply(extraer_op_final)\n",
    "        df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "        print(f\" Procesado bolet√≠n {numero} con {len(df)} documentos.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando bolet√≠n {numero}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTqNby_nV3dq"
   },
   "source": [
    "# Limpiza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FS8VVdQVmou"
   },
   "source": [
    "Existen documentos que no estan asociados a un OP_Numero, se trata de encabezados o finales de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[df_total[\"OP_Numero\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total[df_total[\"OP_Numero\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3CJBp3jV2Hx"
   },
   "source": [
    "Algunos documentos tienen pie de pagina y encabezados dentro del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_pies_pagina(texto):\n",
    "    lineas = texto.splitlines()\n",
    "    nuevas_lineas = []\n",
    "    skip = 0\n",
    "\n",
    "    for i, linea in enumerate(lineas):\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "        if re.match(r\"P√°g\\.\\s*N¬∞\\s*\\d+\", linea.strip()):\n",
    "            skip = 3  # saltar esta l√≠nea y las 3 siguientes\n",
    "            continue\n",
    "        nuevas_lineas.append(linea)\n",
    "\n",
    "    return \"\\n\".join(nuevas_lineas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limpieza\n",
    "df_total[\"Texto_Limpio\"] = df_total[\"Texto\"].apply(eliminar_pies_pagina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.loc[1]['Texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.loc[1]['Texto_Limpio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3jw84RKW7hL"
   },
   "source": [
    "# Modelo para predecir etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                       model=\"hackathon-pln-es/bertin-roberta-base-zeroshot-esnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMMCGalGW-3g"
   },
   "source": [
    "## Texto de ejemplo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\n",
    "    \"El autor se perfila, a los 50 a√±os de su muerte, como uno de los grandes de su siglo\",\n",
    "    candidate_labels=[\"cultura\", \"sociedad\", \"economia\", \"salud\", \"deportes\"],\n",
    "    hypothesis_template=\"Esta oraci√≥n es sobre {}.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17MzMSLpXIuS"
   },
   "source": [
    "## Clasificador de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentClassifier:\n",
    "    \"\"\"\n",
    "    Clasificador autom√°tico de documentos usando BART-large-MNLI\n",
    "    para clasificaci√≥n zero-shot de boletines oficiales\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"facebook/bart-large-mnli\"):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador\n",
    "\n",
    "        Args:\n",
    "            model_name: Nombre del modelo de Hugging Face\n",
    "        \"\"\"\n",
    "        print(\"Cargando modelo BART-large-MNLI...\")\n",
    "        self.classifier = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=model_name,\n",
    "            device=0 if torch.cuda.is_available() else -1  # GPU si est√° disponible\n",
    "        )\n",
    "        print(\"Modelo cargado exitosamente!\")\n",
    "\n",
    "        # Etiquetas para clasificaci√≥n\n",
    "        self.etiquetas_boletin = [\n",
    "            \"Leyes\",\n",
    "            \"Decisiones Administrativas\",\n",
    "            \"Resoluciones Delegadas\",\n",
    "            \"Resoluciones Ministeriales\",\n",
    "            \"Resoluciones (Secretar√≠a de Obras P√∫blicas)\",\n",
    "            \"Licitaciones P√∫blicas\",\n",
    "            \"Adjudicaciones Simples\",\n",
    "            \"Contrataciones Abreviadas\",\n",
    "            \"Concesiones de Agua P√∫blica\",\n",
    "            \"Sentencias\",\n",
    "            \"Sucesorios\",\n",
    "            \"Edictos de Quiebras\",\n",
    "            \"Concursos Civiles o Preventivos\",\n",
    "            \"Edictos Judiciales\",\n",
    "            \"Constituciones de Sociedad\",\n",
    "            \"Asambleas Comerciales\",\n",
    "            \"Asambleas Civiles\",\n",
    "            \"Avisos Generales\",\n",
    "            \"Recaudaci√≥n\"\n",
    "        ]\n",
    "\n",
    "    def preprocess_text(self, text: str, max_length: int = 512) -> str:\n",
    "        \"\"\"\n",
    "        Preprocesa el texto para optimizar la clasificaci√≥n\n",
    "\n",
    "        Args:\n",
    "            text: Texto a procesar\n",
    "            max_length: Longitud m√°xima del texto\n",
    "\n",
    "        Returns:\n",
    "            Texto preprocesado\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "\n",
    "        # Limpiar texto b√°sico\n",
    "        text = text.strip()\n",
    "\n",
    "        # Tomar principalmente el inicio del documento (m√°s informativo)\n",
    "        # y algo del final si es muy largo\n",
    "        if len(text) > max_length:\n",
    "            # Tomar primeros 400 caracteres y √∫ltimos 100\n",
    "            text = text[:400] + \"...\" + text[-100:]\n",
    "\n",
    "        return text\n",
    "\n",
    "    def classify_single_document(self, text: str, threshold: float = 0.5) -> Dict:\n",
    "        \"\"\"\n",
    "        Clasifica un solo documento\n",
    "\n",
    "        Args:\n",
    "            text: Texto del documento\n",
    "            threshold: Umbral m√≠nimo de confianza\n",
    "\n",
    "        Returns:\n",
    "            Diccionario con resultado de clasificaci√≥n\n",
    "        \"\"\"\n",
    "        # Preprocesar texto\n",
    "        processed_text = self.preprocess_text(text)\n",
    "\n",
    "        if not processed_text:\n",
    "            return {\n",
    "                'etiqueta_predicha': 'Sin clasificar',\n",
    "                'confianza': 0.0,\n",
    "                'top_3_etiquetas': [],\n",
    "                'scores_completos': {}\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            # Realizar clasificaci√≥n\n",
    "            resultado = self.classifier(\n",
    "                processed_text,\n",
    "                self.etiquetas_boletin,\n",
    "                multi_label=False\n",
    "            )\n",
    "\n",
    "            # Extraer resultados\n",
    "            etiqueta_principal = resultado['labels'][0]\n",
    "            confianza_principal = resultado['scores'][0]\n",
    "\n",
    "            # Top 3 etiquetas con scores\n",
    "            top_3 = [\n",
    "                {\n",
    "                    'etiqueta': resultado['labels'][i],\n",
    "                    'score': resultado['scores'][i]\n",
    "                }\n",
    "                for i in range(min(3, len(resultado['labels'])))\n",
    "            ]\n",
    "\n",
    "            # Scores completos\n",
    "            scores_completos = dict(zip(resultado['labels'], resultado['scores']))\n",
    "\n",
    "            # Aplicar umbral de confianza\n",
    "            if confianza_principal < threshold:\n",
    "                etiqueta_final = 'Clasificaci√≥n incierta'\n",
    "            else:\n",
    "                etiqueta_final = etiqueta_principal\n",
    "\n",
    "            return {\n",
    "                'etiqueta_predicha': etiqueta_final,\n",
    "                'confianza': confianza_principal,\n",
    "                'top_3_etiquetas': top_3,\n",
    "                'scores_completos': scores_completos\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en clasificaci√≥n: {str(e)}\")\n",
    "            return {\n",
    "                'etiqueta_predicha': 'Error en clasificaci√≥n',\n",
    "                'confianza': 0.0,\n",
    "                'top_3_etiquetas': [],\n",
    "                'scores_completos': {}\n",
    "            }\n",
    "\n",
    "    def classify_dataframe(self, df: pd.DataFrame, text_column: str = 'Texto',\n",
    "                          threshold: float = 0.5, batch_size: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clasifica todos los documentos en un DataFrame\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame con los documentos\n",
    "            text_column: Nombre de la columna con el texto\n",
    "            threshold: Umbral de confianza\n",
    "            batch_size: Tama√±o de lote para procesamiento\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con las clasificaciones agregadas\n",
    "        \"\"\"\n",
    "        print(f\"Clasificando {len(df)} documentos...\")\n",
    "\n",
    "        # Copiar DataFrame para no modificar el original\n",
    "        df_resultado = df.copy()\n",
    "\n",
    "        # Listas para almacenar resultados\n",
    "        etiquetas_predichas = []\n",
    "        confianzas = []\n",
    "        top_3_lists = []\n",
    "\n",
    "        # Procesar en lotes para mostrar progreso\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch_end = min(i + batch_size, len(df))\n",
    "            print(f\"Procesando documentos {i+1}-{batch_end} de {len(df)}\")\n",
    "\n",
    "            # Procesar cada documento en el lote\n",
    "            for idx in range(i, batch_end):\n",
    "                texto = df.iloc[idx][text_column]\n",
    "                resultado = self.classify_single_document(texto, threshold)\n",
    "\n",
    "                etiquetas_predichas.append(resultado['etiqueta_predicha'])\n",
    "                confianzas.append(resultado['confianza'])\n",
    "                top_3_lists.append(resultado['top_3_etiquetas'])\n",
    "\n",
    "        # Agregar resultados al DataFrame\n",
    "        df_resultado['Etiqueta_Predicha'] = etiquetas_predichas\n",
    "        df_resultado['Confianza'] = confianzas\n",
    "        df_resultado['Top_3_Etiquetas'] = top_3_lists\n",
    "\n",
    "        print(\"Clasificaci√≥n completada!\")\n",
    "        return df_resultado\n",
    "\n",
    "    def get_classification_summary(self, df_classified: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Genera un resumen de las clasificaciones\n",
    "\n",
    "        Args:\n",
    "            df_classified: DataFrame con clasificaciones\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con resumen estad√≠stico\n",
    "        \"\"\"\n",
    "        summary = df_classified.groupby('Etiqueta_Predicha').agg({\n",
    "            'Confianza': ['count', 'mean', 'std', 'min', 'max']\n",
    "        }).round(3)\n",
    "\n",
    "        summary.columns = ['Cantidad', 'Confianza_Media', 'Confianza_Std', 'Confianza_Min', 'Confianza_Max']\n",
    "        summary = summary.reset_index()\n",
    "        summary = summary.sort_values('Cantidad', ascending=False)\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def analyze_low_confidence_predictions(self, df_classified: pd.DataFrame,\n",
    "                                         threshold: float = 0.7) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analiza las predicciones con baja confianza para revisi√≥n manual\n",
    "\n",
    "        Args:\n",
    "            df_classified: DataFrame con clasificaciones\n",
    "            threshold: Umbral para considerar baja confianza\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con documentos de baja confianza\n",
    "        \"\"\"\n",
    "        low_confidence = df_classified[df_classified['Confianza'] < threshold].copy()\n",
    "\n",
    "        if len(low_confidence) > 0:\n",
    "            print(f\"Encontrados {len(low_confidence)} documentos con confianza < {threshold}\")\n",
    "            print(\"Estos documentos podr√≠an requerir revisi√≥n manual.\")\n",
    "\n",
    "        return low_confidence.sort_values('Confianza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBHa-y6IXQIe"
   },
   "source": [
    "Instanciamos el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = DocumentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_individual = clasificador.classify_single_document(df_total.iloc[0]['Texto_Limpio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Documento: {df_total.iloc[0]['Texto_Limpio']}...\")\n",
    "print(f\"  Etiqueta predicha: {resultado_individual['etiqueta_predicha']}\")\n",
    "print(f\" Confianza: {resultado_individual['confianza']:.3f}\")\n",
    "print(\" Top 3 etiquetas:\")\n",
    "for i, item in enumerate(resultado_individual['top_3_etiquetas'][:3]):\n",
    "    print(f\"   {i+1}. {item['etiqueta']}: {item['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rVuQPBmY-ac"
   },
   "source": [
    "## Clasificador Masivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentClassifierOptimized:\n",
    "    \"\"\"\n",
    "    Versi√≥n optimizada del clasificador para procesar grandes vol√∫menes de documentos\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"facebook/bart-large-mnli\"):\n",
    "        \"\"\"\n",
    "        Inicializa el clasificador optimizado\n",
    "        \"\"\"\n",
    "        print(\"Cargando modelo BART-large-MNLI...\")\n",
    "\n",
    "        # Configuraci√≥n optimizada del pipeline\n",
    "        self.classifier = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=model_name,\n",
    "            device=0 if torch.cuda.is_available() else -1,\n",
    "            # Optimizaciones de memoria\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            model_kwargs={\n",
    "                \"low_cpu_mem_usage\": True,\n",
    "                \"use_cache\": False  # Reduce memoria\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Modelo cargado en: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "        # Etiquetas para clasificaci√≥n\n",
    "        self.etiquetas_boletin = [\n",
    "            \"Leyes\",\n",
    "            \"Decisiones Administrativas\",\n",
    "            \"Resoluciones Delegadas\",\n",
    "            \"Resoluciones Ministeriales\",\n",
    "            \"Resoluciones (Secretar√≠a de Obras P√∫blicas)\",\n",
    "            \"Licitaciones P√∫blicas\",\n",
    "            \"Adjudicaciones Simples\",\n",
    "            \"Contrataciones Abreviadas\",\n",
    "            \"Concesiones de Agua P√∫blica\",\n",
    "            \"Sentencias\",\n",
    "            \"Sucesorios\",\n",
    "            \"Edictos de Quiebras\",\n",
    "            \"Concursos Civiles o Preventivos\",\n",
    "            \"Edictos Judiciales\",\n",
    "            \"Constituciones de Sociedad\",\n",
    "            \"Asambleas Comerciales\",\n",
    "            \"Asambleas Civiles\",\n",
    "            \"Avisos Generales\",\n",
    "            \"Recaudaci√≥n\"\n",
    "        ]\n",
    "\n",
    "    def preprocess_batch_texts(self, texts: List[str], max_length: int = 400) -> List[str]:\n",
    "        \"\"\"\n",
    "        Preprocesa un lote de textos de manera eficiente\n",
    "        \"\"\"\n",
    "        processed_texts = []\n",
    "\n",
    "        for text in texts:\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                processed_texts.append(\"\")\n",
    "                continue\n",
    "\n",
    "            text = text.strip()\n",
    "\n",
    "            # Truncar texto de manera inteligente\n",
    "            if len(text) > max_length:\n",
    "                # Tomar inicio y final del texto\n",
    "                text = text[:int(max_length*0.8)] + \"...\" + text[-int(max_length*0.2):]\n",
    "\n",
    "            processed_texts.append(text)\n",
    "\n",
    "        return processed_texts\n",
    "\n",
    "    def classify_batch(self, texts: List[str]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Clasifica un lote de textos de manera eficiente\n",
    "        \"\"\"\n",
    "        # Preprocesar lote\n",
    "        processed_texts = self.preprocess_batch_texts(texts)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for text in processed_texts:\n",
    "            if not text:\n",
    "                # Resultado vac√≠o para textos sin contenido\n",
    "                empty_result = {etiqueta: 0.0 for etiqueta in self.etiquetas_boletin}\n",
    "                results.append(empty_result)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Clasificar texto individual\n",
    "                resultado = self.classifier(\n",
    "                    text,\n",
    "                    self.etiquetas_boletin,\n",
    "                    multi_label=False\n",
    "                )\n",
    "\n",
    "                # Convertir a diccionario de scores\n",
    "                scores_dict = dict(zip(resultado['labels'], resultado['scores']))\n",
    "\n",
    "                # Asegurar que todas las etiquetas est√©n presentes\n",
    "                complete_scores = {}\n",
    "                for etiqueta in self.etiquetas_boletin:\n",
    "                    complete_scores[etiqueta] = scores_dict.get(etiqueta, 0.0)\n",
    "\n",
    "                results.append(complete_scores)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando texto: {str(e)[:100]}...\")\n",
    "                # Resultado con scores en 0 en caso de error\n",
    "                error_result = {etiqueta: 0.0 for etiqueta in self.etiquetas_boletin}\n",
    "                results.append(error_result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def classify_dataframe_optimized(self,\n",
    "                                   df: pd.DataFrame,\n",
    "                                   text_column: str,\n",
    "                                   batch_size: int = 8,\n",
    "                                   save_progress: bool = True,\n",
    "                                   checkpoint_every: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clasifica DataFrame completo con optimizaciones para grandes vol√∫menes\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame con documentos\n",
    "            text_column: Nombre de columna con texto\n",
    "            batch_size: Tama√±o de lote (reducido para optimizar memoria)\n",
    "            save_progress: Si guardar progreso peri√≥dicamente\n",
    "            checkpoint_every: Cada cu√°ntos documentos guardar checkpoint\n",
    "\n",
    "        Returns:\n",
    "            DataFrame con columnas de scores para cada etiqueta\n",
    "        \"\"\"\n",
    "        print(f\"Iniciando clasificaci√≥n de {len(df)} documentos...\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Etiquetas a clasificar: {len(self.etiquetas_boletin)}\")\n",
    "\n",
    "        # Copiar DataFrame\n",
    "        df_resultado = df.copy()\n",
    "\n",
    "        # Inicializar columnas de scores\n",
    "        for etiqueta in self.etiquetas_boletin:\n",
    "            df_resultado[f'Score_{etiqueta}'] = 0.0\n",
    "\n",
    "        # Variables para tracking\n",
    "        total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "        start_time = time.time()\n",
    "        processed_docs = 0\n",
    "\n",
    "        # Barra de progreso\n",
    "        pbar = tqdm(total=len(df), desc=\"Clasificando documentos\")\n",
    "\n",
    "        try:\n",
    "            # Procesar en lotes\n",
    "            for batch_idx in range(0, len(df), batch_size):\n",
    "                batch_end = min(batch_idx + batch_size, len(df))\n",
    "\n",
    "                # Extraer textos del lote\n",
    "                batch_texts = df.iloc[batch_idx:batch_end][text_column].tolist()\n",
    "\n",
    "                # Clasificar lote\n",
    "                batch_results = self.classify_batch(batch_texts)\n",
    "\n",
    "                # Asignar resultados al DataFrame\n",
    "                for i, scores_dict in enumerate(batch_results):\n",
    "                    doc_idx = batch_idx + i\n",
    "                    for etiqueta, score in scores_dict.items():\n",
    "                        df_resultado.loc[doc_idx, f'Score_{etiqueta}'] = score\n",
    "\n",
    "                # Actualizar progreso\n",
    "                processed_docs += len(batch_texts)\n",
    "                pbar.update(len(batch_texts))\n",
    "\n",
    "                # Estad√≠sticas de tiempo\n",
    "                elapsed_time = time.time() - start_time\n",
    "                docs_per_second = processed_docs / elapsed_time\n",
    "                remaining_docs = len(df) - processed_docs\n",
    "                eta_seconds = remaining_docs / docs_per_second if docs_per_second > 0 else 0\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Docs/s': f'{docs_per_second:.2f}',\n",
    "                    'ETA': f'{eta_seconds/60:.1f}min'\n",
    "                })\n",
    "\n",
    "                # Checkpoint peri√≥dico\n",
    "                if save_progress and processed_docs % checkpoint_every == 0:\n",
    "                    checkpoint_file = f'classification_checkpoint_{processed_docs}.pkl'\n",
    "                    df_resultado.to_pickle(checkpoint_file)\n",
    "                    # Ahora lo descarg√°s autom√°ticamente\n",
    "\n",
    "                    print(f\"\\nCheckpoint guardado: {checkpoint_file}\")\n",
    "\n",
    "                # Limpiar memoria peri√≥dicamente\n",
    "                if batch_idx % (batch_size * 10) == 0:\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "        finally:\n",
    "            pbar.close()\n",
    "\n",
    "        # Agregar columnas de an√°lisis\n",
    "        df_resultado = self._add_analysis_columns(df_resultado)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n‚úÖ Clasificaci√≥n completada!\")\n",
    "        print(f\"‚è±Ô∏è  Tiempo total: {total_time/60:.2f} minutos\")\n",
    "        print(f\"üìä Velocidad promedio: {len(df)/total_time:.2f} docs/segundo\")\n",
    "\n",
    "        return df_resultado\n",
    "\n",
    "    def _add_analysis_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Agrega columnas de an√°lisis basadas en los scores\n",
    "        \"\"\"\n",
    "        print(\"Agregando columnas de an√°lisis...\")\n",
    "\n",
    "        # Columnas de scores\n",
    "        score_columns = [col for col in df.columns if col.startswith('Score_')]\n",
    "\n",
    "        # Etiqueta con mayor score\n",
    "        df['Etiqueta_Predicha'] = df[score_columns].idxmax(axis=1).str.replace('Score_', '')\n",
    "\n",
    "        # Confianza m√°xima\n",
    "        df['Confianza_Maxima'] = df[score_columns].max(axis=1)\n",
    "\n",
    "        # Top 3 etiquetas\n",
    "        def get_top_3(row):\n",
    "            scores = [(col.replace('Score_', ''), row[col]) for col in score_columns]\n",
    "            scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            return scores[:3]\n",
    "\n",
    "        df['Top_3_Etiquetas'] = df.apply(get_top_3, axis=1)\n",
    "\n",
    "        # Diferencia entre top 2 (indica certeza)\n",
    "        def get_confidence_gap(row):\n",
    "            scores = [row[col] for col in score_columns]\n",
    "            scores.sort(reverse=True)\n",
    "            return scores[0] - scores[1] if len(scores) > 1 else 0\n",
    "\n",
    "        df['Gap_Confianza'] = df.apply(get_confidence_gap, axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_classification_summary(self, df_classified: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Genera resumen estad√≠stico de las clasificaciones\n",
    "        \"\"\"\n",
    "        print(\"Generando resumen de clasificaci√≥n...\")\n",
    "\n",
    "        summary = df_classified.groupby('Etiqueta_Predicha').agg({\n",
    "            'Confianza_Maxima': ['count', 'mean', 'std', 'min', 'max'],\n",
    "            'Gap_Confianza': 'mean'\n",
    "        }).round(4)\n",
    "\n",
    "        summary.columns = ['Cantidad', 'Confianza_Media', 'Confianza_Std',\n",
    "                          'Confianza_Min', 'Confianza_Max', 'Gap_Promedio']\n",
    "        summary = summary.reset_index()\n",
    "        summary = summary.sort_values('Cantidad', ascending=False)\n",
    "\n",
    "        # Calcular porcentajes\n",
    "        summary['Porcentaje'] = (summary['Cantidad'] / len(df_classified) * 100).round(2)\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def save_results(self, df_classified: pd.DataFrame, filename: str = \"documentos_clasificados\"):\n",
    "        \"\"\"\n",
    "        Guarda los resultados en m√∫ltiples formatos\n",
    "        \"\"\"\n",
    "        print(f\"Guardando resultados como {filename}...\")\n",
    "\n",
    "        # Guardar DataFrame completo\n",
    "        df_classified.to_pickle(f\"{filename}.pkl\")\n",
    "        df_classified.to_csv(f\"{filename}.csv\", index=False)\n",
    "\n",
    "        # Guardar solo scores en archivo separado\n",
    "        score_columns = [col for col in df_classified.columns if col.startswith('Score_')]\n",
    "        analysis_columns = ['Etiqueta_Predicha', 'Confianza_Maxima', 'Gap_Confianza']\n",
    "\n",
    "        df_scores = df_classified[score_columns + analysis_columns]\n",
    "        df_scores.to_csv(f\"{filename}_scores_only.csv\", index=False)\n",
    "\n",
    "        print(\"‚úÖ Resultados guardados!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n 2: Usando la clase (m√°s control)\n",
    "classifier = DocumentClassifierOptimized()\n",
    "df_classified = classifier.classify_dataframe_optimized(\n",
    "    df=df_total,\n",
    "    text_column=\"Texto_Limpio\",\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que termina tu an√°lisis y guard√°s el archivo\n",
    "df_classified.to_csv(\"resumen.csv\", index=False)\n",
    "\n",
    "# Ahora lo descarg√°s autom√°ticamente\n",
    "files.download(\"resumen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dWC8Sh8rUPq"
   },
   "source": [
    "# Prediccion en la Busqueda de Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Importar librer√≠as\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "file_path = \"/content/resumen.csv\"\n",
    "# Aumentar el l√≠mite de campo para campos muy largos\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# Forzar lectura tolerante a errores y texto largo\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_ALL,  # requiere que todos los campos est√©n entre comillas\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"warn\"  # mostrar advertencias si encuentra l√≠neas mal formadas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaz√° por la ruta correcta de tu archivo\n",
    "#df = pd.read_pickle(\"/content/classification_checkpoint_15000.pkl\")\n",
    "\n",
    "# Verific√° los primeros registros\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Texto_Limpio\"])  # aseguramos que no haya nulos\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Opcional: Previsualizaci√≥n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAosAdlMvMb5"
   },
   "source": [
    "## Evaluacion de la Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR3AP8FivO1V"
   },
   "source": [
    "Evaluaci√≥n de la Clasificaci√≥n Autom√°tica ‚Äì Validaci√≥n por Muestreo\n",
    "Para validar el rendimiento del modelo de clasificaci√≥n autom√°tica sin etiquetar manualmente los 15.000 documentos, aplicamos estad√≠stica inferencial para determinar un tama√±o de muestra representativo.\n",
    "\n",
    "Par√°metros definidos:\n",
    "Tama√±o de poblaci√≥n (N): 15.000 documentos\n",
    "\n",
    "Nivel de confianza: 90%\n",
    "\n",
    "Margen de error permitido: ¬±10%\n",
    "\n",
    "Proporci√≥n esperada (p): 0.5 (caso conservador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Par√°metros\n",
    "N = 15114           # Poblaci√≥n\n",
    "Z = 1.645           # Z-score para 90% confianza\n",
    "e = 0.10            # Margen de error\n",
    "p = 0.5             # Proporci√≥n esperada\n",
    "\n",
    "# Tama√±o de muestra sin correcci√≥n\n",
    "n_0 = (Z**2 * p * (1 - p)) / (e**2)\n",
    "\n",
    "# Correcci√≥n poblacional finita\n",
    "n = n_0 / (1 + (n_0 - 1) / N)\n",
    "n = int(np.ceil(n))\n",
    "\n",
    "print(f\"üìè Tama√±o √≥ptimo de muestra: {n} documentos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muestra = df.sample(n=n, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muestra.to_excel(\"muestra_validacion_modelo.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruir el dataset entregado por el usuario\n",
    "data = {\n",
    "    \"Etiqueta_Predicha\": [\n",
    "        \"Resoluciones Delegadas\", \"Adjudicaciones Simples\", \"Contrataciones Abreviadas\", \"Licitaciones P√∫blicas\",\n",
    "        \"Contrataciones Abreviadas\", \"Sucesorios\", \"Asambleas Comerciales\", \"Edictos de Quiebras\", \"Contrataciones Abreviadas\",\n",
    "        \"Resoluciones Ministeriales\", \"Sucesorios\", \"Constituciones de Sociedad\", \"Concursos Civiles o Preventivos\",\n",
    "        \"Sucesorios\", \"Contrataciones Abreviadas\", \"Resoluciones (Secretar√≠a de Obras P√∫blicas)\", \"Decisiones Administrativas\",\n",
    "        \"Resoluciones Ministeriales\", \"Decisiones Administrativas\", \"Sucesorios\", \"Asambleas Comerciales\", \"Licitaciones P√∫blicas\",\n",
    "        \"Sucesorios\", \"Sucesorios\", \"Resoluciones Ministeriales\", \"Sentencias\", \"Contrataciones Abreviadas\",\n",
    "        \"Concesiones de Agua P√∫blica\", \"Resoluciones Ministeriales\", \"Edictos de Quiebras\", \"Decisiones Administrativas\",\n",
    "        \"Decisiones Administrativas\", \"Decisiones Administrativas\", \"Sucesorios\", \"Sucesorios\", \"Sucesorios\",\n",
    "        \"Resoluciones Ministeriales\", \"Resoluciones Delegadas\", \"Leyes\", \"Contrataciones Abreviadas\", \"Sucesorios\",\n",
    "        \"Resoluciones Ministeriales\", \"Contrataciones Abreviadas\", \"Adjudicaciones Simples\", \"Sentencias\",\n",
    "        \"Resoluciones Ministeriales\", \"Sucesorios\", \"Recaudaci√≥n\", \"Leyes\", \"Adjudicaciones Simples\",\n",
    "        \"Contrataciones Abreviadas\", \"Licitaciones P√∫blicas\", \"Resoluciones Ministeriales\", \"Asambleas Comerciales\",\n",
    "        \"Contrataciones Abreviadas\", \"Sucesorios\", \"Sucesorios\", \"Resoluciones Delegadas\", \"Contrataciones Abreviadas\",\n",
    "        \"Sucesorios\", \"Edictos de Quiebras\", \"Sentencias\", \"Adjudicaciones Simples\", \"Contrataciones Abreviadas\",\n",
    "        \"Licitaciones P√∫blicas\", \"Decisiones Administrativas\", \"Licitaciones P√∫blicas\"\n",
    "    ],\n",
    "    \"Etiqueta_Verdadera\": [\n",
    "        \"Avisos Generales\", \"Adjudicaciones Simples\", \"Contrataciones Abreviadas\", \"Licitaciones P√∫blicas\",\n",
    "        \"Contrataciones Abreviadas\", \"Sucesorios\", \"Asambleas Comerciales\", \"Edictos de Quiebras\", \"POSESIONES VEINTEA√ëALES\",\n",
    "        \"Decretos\", \"Sucesorios\", \"Constituciones de Sociedad\", \"REMATES JUDICIALES\", \"Sucesorios\", \"Contrataciones Abreviadas\",\n",
    "        \"Resoluciones (Secretar√≠a de Obras P√∫blicas)\", \"Decisiones Administrativas\", \"ASAMBLEAS CIVILES\",\n",
    "        \"Decisiones Administrativas\", \"Sucesorios\", \"Avisos Comerciales\", \"CONVOCATORIAS A AUDIENCIA P√öBLICA\",\n",
    "        \"Sucesorios\", \"Sucesorios\", \"Decretos\", \"POSESIONES VEINTEA√ëALES\", \"Contrataciones Abreviadas\",\n",
    "        \"Concesiones de Agua P√∫blica\", \"Resoluciones Ministeriales\", \"Edictos de Quiebras\", \"NOTIFICACIONES ADMINISTRATIVAS\",\n",
    "        \"Decisiones Administrativas\", \"Decisiones Administrativas\", \"Sucesorios\", \"Sucesorios\", \"Sucesorios\",\n",
    "        \"Resoluciones Delegadas\", \"Resoluciones Delegadas\", \"NOTIFICACIONES ADMINISTRATIVAS\", \"Contrataciones Abreviadas\",\n",
    "        \"Sucesorios\", \"Resoluciones Delegadas\", \"Contrataciones Abreviadas\", \"Adjudicaciones Simples\", \"EDICTOS DE MINAS\",\n",
    "        \"DECRETOS\", \"Sucesorios\", \"NOTIFICACIONES ADMINISTRATIVAS\", \"EDICTOS DE MINAS\", \"Adjudicaciones Simples\",\n",
    "        \"Contrataciones Abreviadas\", \"Licitaciones P√∫blicas\", \"Resoluciones Ministeriales\", \"Asambleas Comerciales\",\n",
    "        \"Contrataciones Abreviadas\", \"Sucesorios\", \"Sucesorios\", \"Resoluciones Delegadas\", \"Contrataciones Abreviadas\",\n",
    "        \"Sucesorios\", \"Edictos de Quiebras\", \"NOTIFICACIONES ADMINISTRATIVAS\", \"Adjudicaciones Simples\",\n",
    "        \"Contrataciones Abreviadas\", \"Licitaciones P√∫blicas\", \"Decisiones Administrativas\", \"Licitaciones P√∫blicas\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame\n",
    "df_eval = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar etiquetas verdaderas no vistas por el modelo\n",
    "etiquetas_predichas = set(df_eval[\"Etiqueta_Predicha\"])\n",
    "etiquetas_verdaderas = set(df_eval[\"Etiqueta_Verdadera\"])\n",
    "etiquetas_desconocidas = etiquetas_verdaderas - etiquetas_predichas\n",
    "\n",
    "# Filtrar para el reporte solo etiquetas evaluables\n",
    "df_eval_filtrado = df_eval[~df_eval[\"Etiqueta_Verdadera\"].isin(etiquetas_desconocidas)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear reporte\n",
    "reporte = classification_report(\n",
    "    df_eval_filtrado[\"Etiqueta_Verdadera\"],\n",
    "    df_eval_filtrado[\"Etiqueta_Predicha\"],\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reporte = pd.DataFrame(reporte).transpose()\n",
    "df_reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_desconocidas_sorted = sorted(etiquetas_desconocidas)\n",
    "etiquetas_desconocidas_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de confusi√≥n\n",
    "y_true = df_eval_filtrado[\"Etiqueta_Verdadera\"]\n",
    "y_pred = df_eval_filtrado[\"Etiqueta_Predicha\"]\n",
    "labels = sorted(y_true.unique())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Crear el heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Etiqueta Predicha\")\n",
    "plt.ylabel(\"Etiqueta Verdadera\")\n",
    "plt.title(\"Matriz de Confusi√≥n\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calcular accuracy general\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v99ZRfVmvnzv"
   },
   "source": [
    "## Prediccion de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear embeddings con un modelo de Hugging Face\n",
    "# Usamos un modelo multiling√ºe adecuado para textos legales\n",
    "modelo = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Convertimos cada contenido a un vector (embedding)\n",
    "corpus = df['Texto_Limpio'].tolist()\n",
    "embeddings = modelo.encode(corpus, show_progress_bar=True)\n",
    "\n",
    "# Convertimos a matriz numpy\n",
    "embedding_matrix = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Indexar embeddings con FAISS (b√∫squeda r√°pida por similitud)\n",
    "dim = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_respuesta(pregunta, top_k=5, mostrar=True):\n",
    "    \"\"\"\n",
    "    Busca los documentos m√°s relevantes para una pregunta usando embeddings sem√°nticos.\n",
    "\n",
    "    Args:\n",
    "        pregunta (str): pregunta del usuario\n",
    "        top_k (int): cantidad de documentos a mostrar\n",
    "        mostrar (bool): si se desea imprimir resultados o no\n",
    "\n",
    "    Returns:\n",
    "        df_resultado (pd.DataFrame): sub-DataFrame con los documentos m√°s similares\n",
    "        lista_indices (List[int]): lista de √≠ndices del DataFrame original\n",
    "    \"\"\"\n",
    "    pregunta_emb = modelo.encode([pregunta])\n",
    "    D, I = index.search(np.array(pregunta_emb), top_k)\n",
    "\n",
    "    indices = I[0].tolist()\n",
    "    distancias = D[0]\n",
    "    resultados = df.iloc[indices].copy()\n",
    "    resultados[\"Distancia\"] = distancias\n",
    "\n",
    "    if mostrar:\n",
    "        for i, (idx, dist) in enumerate(zip(indices, distancias)):\n",
    "            print(f\"\\nüîé Documento {i+1} (Distancia {dist:.2f})\")\n",
    "            print(f\"OP_Numero: {df.iloc[idx]['OP_Numero']}\")\n",
    "            print(f\"Contenido:\\n{df.iloc[idx]['Texto_Limpio'][:2000]}...\")\n",
    "\n",
    "    return resultados, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6: Probar el sistema\n",
    "pregunta = \"¬øQu√© documentos mencionan adjudicaciones?\"\n",
    "resultados = buscar_respuesta(pregunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['OP_Numero']==\"100114953\"]['Texto_Limpio'].values[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
