# README - ClasificaciÃ³n AutomÃ¡tica de Documentos del BoletÃ­n Oficial

## ğŸ—‚ï¸ DescripciÃ³n General
Este proyecto aborda un desafÃ­o de Procesamiento de Lenguaje Natural (NLP) aplicado a documentos administrativos del Estado. Su objetivo es automatizar la clasificaciÃ³n temÃ¡tica de documentos publicados en boletines oficiales, permitiendo una bÃºsqueda mÃ¡s eficiente y una comprensiÃ³n semÃ¡ntica de grandes volÃºmenes de texto. Para lograrlo, se integran tÃ©cnicas modernas de NLP con arquitecturas preentrenadas, embebido semÃ¡ntico y modelos de inferencia `zero-shot`.

El pipeline completo abarca desde la descarga de boletines oficiales hasta su clasificaciÃ³n automÃ¡tica y posterior bÃºsqueda semÃ¡ntica a travÃ©s de preguntas en lenguaje natural.

---

## ğŸ“ Estructura del Proyecto
```
project_root/
â”‚
â”œâ”€â”€ boletines.zip                  # Archivo original descargado desde Google Drive
â”œâ”€â”€ boletines_extraidos/          # Carpeta donde se extraen los PDFs
â”‚   â””â”€â”€ Boletines/
â”‚       â””â”€â”€ boletines_2024/       # Contiene todos los PDFs individuales
â”œâ”€â”€ classification_checkpoint_*.pkl # Checkpoints periÃ³dicos durante la clasificaciÃ³n
â”œâ”€â”€ resumen.csv                   # Archivo CSV con los resultados finales
â””â”€â”€ Austral_Entrega_Final_NLP_Boletines.ipynb # Notebook principal
```

---

## ğŸ” Diagrama de Flujo del Proceso

```mermaid
graph TD
    A[Inicio] --> B[Descarga de PDF desde Drive]
    B --> C[ExtracciÃ³n de documentos con expresiones regulares]
    C --> D[Limpieza del texto (pies de pÃ¡gina, encabezados)]
    D --> E[CreaciÃ³n de DataFrame consolidado]
    E --> F[ClasificaciÃ³n con modelo Zero-Shot]
    F --> G[AnÃ¡lisis y resumen de etiquetas]
    F --> H[Checkpoint y guardado]
    E --> I[Embeddings con SentenceTransformer]
    I --> J[Ãndice FAISS para bÃºsqueda]
    J --> K[BÃºsqueda semÃ¡ntica por similitud textual]
```

---

## ğŸ¤– Componentes de NLP y su OperaciÃ³n

### 1. Preprocesamiento de Documentos
Se descargan PDFs desde un enlace de Google Drive, se extrae su texto ignorando las primeras pÃ¡ginas (Ã­ndices) y se segmenta cada boletÃ­n en documentos individuales. La segmentaciÃ³n se realiza utilizando expresiones regulares que detectan patrones como `OP NÂº: XXXXXXX`, caracterÃ­sticos de los boletines oficiales.

Posteriormente se eliminan encabezados y pies de pÃ¡gina que interfieren en el anÃ¡lisis semÃ¡ntico.

### 2. Modelos de ClasificaciÃ³n Zero-Shot
Utilizamos el modelo `facebook/bart-large-mnli`, entrenado en tareas de inferencia textual (NLI), que permite aplicar una tÃ©cnica denominada **zero-shot learning**. En lugar de requerir datos etiquetados para entrenamiento, el modelo puede inferir a quÃ© categorÃ­a pertenece un texto usando hipÃ³tesis semÃ¡nticas del tipo:

> "Este documento trata sobre licitaciones pÃºblicas."

Se compara la probabilidad de esta hipÃ³tesis para mÃºltiples etiquetas candidatas.

### 3. Clasificador Optimizado
Se implementa una clase `DocumentClassifierOptimized` que permite:
- Preprocesamiento por lotes.
- ClasificaciÃ³n eficiente con reducciÃ³n de memoria.
- Checkpoints periÃ³dicos para no perder el progreso.

Este enfoque resulta fundamental cuando se trabaja con mÃ¡s de 15.000 documentos y se requiere procesamiento en GPU con eficiencia.

### 4. BÃºsqueda SemÃ¡ntica por Pregunta
Se integra un sistema de recuperaciÃ³n de informaciÃ³n basado en embeddings semÃ¡nticos:
- Se usa `SentenceTransformer` para representar cada documento como un vector en un espacio semÃ¡ntico.
- Se indexan estos vectores con `FAISS` para realizar consultas rÃ¡pidas por distancia coseno o L2.
- Se ingresa una pregunta en lenguaje natural (ej: "Â¿QuÃ© documentos mencionan adjudicaciones?") y el sistema devuelve los documentos mÃ¡s relevantes.

Este componente transforma una bÃºsqueda tradicional en una bÃºsqueda inteligente, capaz de encontrar documentos aun cuando no contienen literalmente las palabras de la pregunta.

---

## ğŸ§  Â¿QuÃ© es Zero-Shot Learning y por quÃ© es Ãºtil?
Zero-shot learning permite clasificar texto sin necesidad de entrenamiento adicional. Funciona mediante la evaluaciÃ³n de la relaciÃ³n semÃ¡ntica entre el texto de entrada y una lista de hipÃ³tesis etiquetadas. En nuestro caso, las hipÃ³tesis fueron diseÃ±adas en espaÃ±ol para reflejar categorÃ­as tÃ­picas de los boletines oficiales:

- "Este documento trata sobre leyes."
- "Este documento trata sobre resoluciones ministeriales."

La ventaja de este enfoque es que no se requiere un dataset previamente etiquetado. Se puede aplicar a nuevos dominios (como documentos administrativos) sin necesidad de fine-tuning.

---

## ğŸ“Š Etiquetas Utilizadas
Las 19 etiquetas semÃ¡nticas definidas incluyen:
- Leyes
- Decisiones Administrativas
- Resoluciones Ministeriales
- Licitaciones PÃºblicas
- Contrataciones Abreviadas
- Sentencias
- Edictos Judiciales
- RecaudaciÃ³n
- etc.

Estas categorÃ­as permiten una clasificaciÃ³n temÃ¡tica detallada y Ãºtil para tareas legales, administrativas y de transparencia.

---

## ğŸŒ TecnologÃ­as Usadas
- **Python 3.11**
- **Hugging Face Transformers**
- **PyMuPDF (fitz)** para extracciÃ³n de texto de PDF
- **pandas**, **numpy**, **tqdm** para manipulaciÃ³n y visualizaciÃ³n
- **sentence-transformers** para embeddings
- **FAISS** para bÃºsqueda eficiente
- **Google Colab** para entrenamiento en GPU

---

## ğŸ“œ Ejemplo de Uso
```python
pregunta = "Â¿QuÃ© documentos mencionan adjudicaciones?"
resultados, indices = buscar_respuesta(pregunta)
```
Esto devuelve los documentos que, semÃ¡nticamente, se relacionan con adjudicaciones, aunque no contengan la palabra literal.

---

## ğŸš€ Resultados
- Se procesaron **+15.000 documentos** extraÃ­dos desde PDFs del boletÃ­n oficial.
- Se clasificaron en **19 categorÃ­as** sin entrenamiento supervisado.
- Se generÃ³ un sistema de bÃºsqueda inteligente capaz de responder preguntas.
- Se logrÃ³ un pipeline automatizado, reproducible y escalable para tareas administrativas y legales.

---

## ğŸ“„ Autor
Trabajo final de la materia **Procesamiento de Lenguaje Natural**, Universidad Austral.

**Cristian Salinas**

---

## ğŸ”§ Mejoras Futuras
- Entrenamiento supervisado con dataset etiquetado para aumentar la precisiÃ³n.
- IncorporaciÃ³n de OCR para textos escaneados (no seleccionables).
- Interfaz web de usuario para exploraciÃ³n interactiva.
- ExportaciÃ³n de resultados a bases de datos relacionales o APIs REST.

---

## ğŸ” Licencia
MIT License.

---

## âœ… EvaluaciÃ³n del Modelo de ClasificaciÃ³n (Muestra Manual)

Se evaluÃ³ el rendimiento del modelo sobre una muestra aleatoria de 68 documentos del BoletÃ­n Oficial, los cuales fueron etiquetados manualmente. Para garantizar una evaluaciÃ³n justa, se eliminaron del anÃ¡lisis aquellas **etiquetas verdaderas que el modelo nunca predijo**, ya que no formaban parte de las categorÃ­as previstas.

### âŒ Etiquetas verdaderas no evaluables (no disponibles en el modelo)

```
ASAMBLEAS CIVILES
Avisos Comerciales
Avisos Generales
CONVOCATORIAS A AUDIENCIA PÃšBLICA
DECRETOS
Decretos
EDICTOS DE MINAS
NOTIFICACIONES ADMINISTRATIVAS
POSESIONES VEINTEAÃ‘ALES
REMATES JUDICIALES
```

Estas categorÃ­as fueron eliminadas del cÃ¡lculo de mÃ©tricas para no afectar negativamente al modelo con clases que no estaba diseÃ±ado para reconocer.

---

### ğŸ“Š MÃ©tricas de DesempeÃ±o

Luego del filtrado, el modelo alcanzÃ³ una **accuracy global de 96.1%**, con los siguientes resultados por clase:

```python
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))
```

> ğŸ“Œ PodÃ©s consultar el DataFrame `df_reporte` para ver la tabla completa en el notebook.

---

### ğŸ§® Matriz de ConfusiÃ³n

La siguiente matriz permite visualizar los aciertos (diagonal) y los errores de predicciÃ³n (fuera de la diagonal):

```python
from sklearn.metrics import confusion_matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
```

---

### ğŸ“Œ ConclusiÃ³n

- El modelo demostrÃ³ **alto rendimiento general** y buena capacidad de generalizaciÃ³n, especialmente considerando que se trata de un sistema `zero-shot`.
- Las confusiones mÃ¡s frecuentes se observaron entre etiquetas conceptualmente similares, como:
  - *Resoluciones Delegadas* â†” *Resoluciones Ministeriales*
  - *Sentencias* â†” *Edictos de Minas* (ambos tipos judiciales)
- La performance sugiere que el modelo es adecuado para tareas de clasificaciÃ³n inicial y bÃºsqueda inteligente en documentos administrativos.
